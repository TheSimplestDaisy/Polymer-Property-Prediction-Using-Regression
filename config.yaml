# =====================
# Training configuration
# =====================
file_path: 'data/pretrain.csv'

epochs: 30
batch_size: 16
lr_rate: 0.00005
scheduler_type: 'linear'
weight_decay: 0.0
warmup_ratio: 0.05
save_strategy: 'epoch'
overwrite_output_dir: true
save_total_limit: 3
fp16: false
logging_strategy: 'epoch'
evaluation_strategy: 'epoch'
report_to: 'tensorboard'
dataloader_num_workers: 2
sharded_ddp: false
save_path: 'ckpt/pretrain.pt'
load_checkpoint: false

# =====================
# Model architecture
# =====================
max_position_embeddings: 514
blocksize: 175
num_attention_heads: 12
num_hidden_layers: 6
hidden_dropout_prob: 0.1
attention_probs_dropout_prob: 0.1
mlm_probability: 0.15
